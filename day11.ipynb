{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import MetadataMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model = \"granite3.2:2b\")\n",
    "Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.extractors import (SummaryExtractor,QuestionsAnsweredExtractor,TitleExtractor,KeywordExtractor,BaseExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index-extractors-entity --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.extractors.entity import EntityExtractor\n",
    "from llama_index.core.node_parser import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splitter = TokenTextSplitter(separator=' ', chunk_size=1200, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractors = [\n",
    "    TitleExtractor(nodes = 5),\n",
    "    QuestionsAnsweredExtractor(questions=3),\n",
    "    # SummaryExtractor(),\n",
    "    # KeywordExtractor(),\n",
    "    # EntityExtractor(),\n",
    "    # BaseExtractor()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [test_splitter] + extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "docs = SimpleDirectoryReader(input_files=['./data/Tulu_Language_Text_Recognition_and_Translation.pdf']).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='8e68779c-1900-4b8c-9903-98384a62283c', embedding=None, metadata={'page_label': '1', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Tulu Language Text Recognition and\\nTranslation\\nPRATHWINI1, ANISHA P RODRIGUES2, P. VIJAYA3, ROSHAN FERNANDES4*\\n1Department of Master of Computer Applications, NMAM Institute of Technology, NITTE(Deemed to be University), India\\n(e-mail:prathwini.devadiga@nitte.edu.in)\\n2Department of Computer Science and Engineering, NMAM Institute of Technology, NITTE(Deemed to be University), India (e-mail:anishapr@nitte.edu.in)\\n3Department of Mathematics and Computer Science, Modern College of Business and Sciences, Bowshar, Sultanate of Oman (e-mail:pvvijaya@gmail.com)\\n4Department of Computer Science and Engineering, NMAM Institute of Technology, NITTE(Deemed to be University), India\\n(e-mail:roshan_nmamit@nitte.edu.in)\\nCorresponding author: Roshan Fernandes (e-mail: roshan_nmamit@nitte.edu.in)\\nABSTRACT Language is a primary means of communication, but it is not the only means; knowing a\\nlanguage does, however, assist speed up the process. Many distinct languages are spoken worldwide, and\\npeople use them to communicate. This is only one of the many reasons why language is so crucial. Based\\non the literature survey, it is evident that there is a lack of available translators for the Tulu language.\\nDespite being prevalent predominantly in Karnataka, the Tulu language has not been as widely spoken as\\nother Indian languages until recently, although it gained enough recognition to become the second language\\nin Karnataka. The purpose of our research work aims at translating the English language into the Tulu\\nlanguage. During the evaluation the system was tested on a dataset consisting of handwritten characters\\nduring the evaluation process Convolutional Neural Networks used achieved an accuracy rate of 92%. To\\ntranslate English to the Tulu language, we employed a parallel sentence dataset for the neural approach and\\na parallel word dataset for the rule-based approach. The rule-based approach resulted in an 89% accuracy\\nrate for word-based analysis and an 81% accuracy rate for sentence-based analysis for the English-to-Tulu\\nlanguage translation. The neural machine translation approach of the Encoder-Decoder model with LSTM\\nis been used to accomplish translation from English to Tulu with a BLEU score of 0.83 and Tulu to English\\nwith a BLUE score of 0.65. The model also employed hybrid machine translation to enhance the translation.\\nINDEX TERMS Machine Translation, Rule-based method, Neural Network Translation, Convolutional\\nNeural Network (CNN), Encoder-Decoder Model, and Long short-term memory (LSTM)\\nI. INTRODUCTION\\nLanguage, as a means of communication, encompasses a\\ncollection of written symbols and sounds used by individ-\\nuals within a specific region or country for oral or written\\nexpression. It sets humans apart and involves acquiring a\\ncomplex framework of vocabulary, structure, and syntax for\\neffective communication. Indian languages are categorized\\ninto families such as Indo-Iranian or Indo-European, Munda,\\nDravidian, Austroasiatic, Sino-Tibetan, and Tibeto-Burman.\\nThe Indian constitution mentions twenty-two of these lan-\\nguages. India’s multilingual nature is evident across its states,\\nalthough fluency in every language spoken within the nation\\nisn’t universal. Tulu, from the Dravidian family, is spoken\\npredominantly in the southern region of Dakshina Kannada\\nand Udupi districts in Karnataka, and in Kasaragod district\\nin southwestern India. Tuluva, the indigenous people, reside\\nin Tulu Nadu. Presently, Tulu is formally acknowledged as\\nthe second language of Karnataka, with ongoing efforts to\\ninclude it in the 8th Schedule of the Constitution. It contains\\nfour dialects, mainly used for inter-community communica-\\ntion, trade, and entertainment. Tulu is spoken across various\\nregions like Mangalore, Udupi, Karkala, Belthangady, Kun-\\ndapura, Kasaragod, Manjeshwar, Puttur Sullia, and Bantwal,\\nwith different dialects in each area. Efforts are underway to\\ninclude Tulu in the Constitution’s 8th Schedule. Machine\\ntranslation (MT), a crucial aspect of natural language pro-\\ncessing, has evolved significantly. Rule-based machine trans-\\nlation (RBMT) is an early approach to language translation\\nusing predefined linguistic rules. These systems analyze in-\\nput sentences, break them down into grammatical parts, and\\nthen apply linguistic rules to generate the translated output in\\na target language. RBMT operates in three phases: analyzing\\nthe input sentence, transferring the linguistic elements into\\nthe target language, and finally, generating the translated sen-\\nVOLUME , 2023 1\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='52ad48dd-a07d-4506-9db6-87ddc43cd899', embedding=None, metadata={'page_label': '2', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"tence. However, RBMT’s reliance on manually constructed\\nrules limited its adaptability to handle the complexities of\\nnatural languages. This led to the development of more\\nadvanced translation methods like neural machine translation\\n(NMT). End-to-end neural machine translation (NMT) has\\nbecome dominant, departing from earlier rule-based systems\\nthat heavily relied on manually crafted translation rules and\\nlinguistic knowledge. NMT utilizes computer systems to\\ntranslate languages and has shown remarkable success com-\\npared to earlier rule-based methods, which required exten-\\nsive linguistic rules for translation between languages. NMT\\nhas streamlined translation processes and improved results.\\nFollowing are some of the significant contributions of the\\nproposed work:\\n• The data set, consisting of 30,500 manually collected\\nTulu handwritten characters, was compiled for the pro-\\nposed work.\\n• To recognize the Tulu language script, both the CNN\\nalgorithm and other machine learning algorithms were\\nutilized.\\n• A dataset comprising 1458 words and 1000 English-to-\\nTulu sentences was manually collected. Rule-based and\\nneural machine techniques were employed to translate\\nEnglish to Tulu.\\n• The English-to-Tulu language translation was accom-\\nplished through the application of both rule-based and\\nneural machine techniques.\\n• To achieve backward translation from Tulu to English,\\nthe Encoder-Decoder model with LSTM has been uti-\\nlized, employing the neural machine translation ap-\\nproach.\\n• Hybrid machine translation was employed by combin-\\ning rule-based and neural machine translation to im-\\nprove the performance of the model.\\nII. RELATED WORKS\\nIn this section, we elaborate on our efforts in handwritten\\ncharacter recognition and English-to-Tulu language trans-\\nlation, employing various methods. To address the identi-\\nfication of human emotions, we conduct a literature sur-\\nvey to understand and pinpoint the limitations of current\\ntechniques. [1] Manimozhi’s software focuses on precise\\nrecognition of handwritten Tulu characters, aiding in trans-\\nforming historical manuscripts. [2] Seshikala et al.’s study\\nevaluates CNN models for Devanagari characters, emphasiz-\\ning computational efficiency in their specialized architecture.\\n[3] Anush Bijoor’s research rejuvenates the ancient Tulu\\nalphabet using CNNs for character recognition, aiming to\\ntransform historical manuscripts. [4] Savitha et al.’s method\\nutilizes image preprocessing techniques to enhance character\\nrecognition accuracy. [5] Rao et al. explore machine-learning\\nmethods for Tulu characters, emphasizing CNN’s efficiency\\nin recognition. [6] Memon et al. present a user-friendly\\napproach for Kannada character recognition employing deep\\nlearning algorithms. [7] Albahli’s summary explores hand-\\nwritten document recognition and potential future research\\ndirections based on an SLR. [8] Bora et al. propose a multi-\\nstep approach using enhanced Faster-RCNN for numeral\\nrecognition from images. [9] Deore et al. combine CNN and\\nECOC classifiers for accurate OCR of handwritten charac-\\nters. [10] Khandokar et al. introduce a dataset and a VGG16\\nmodel for Devanagari character recognition. [11] Guha et al.\\nexplore CNN’s capacity in recognizing complex handwritten\\ncharacters with a dataset achieving 92.91% accuracy. [12]\\nRani et al. emphasize CNN’s role in automatic feature ex-\\ntraction for character recognition, specifically in Devanagari\\nscript. [13] Hamdan et al. design a capsule network for\\neffective Kannada character recognition. [14] Vinjit et al.\\ncompare various approaches for handwriting recognition,\\nincluding statistical methods and neural networks. [15] Rani\\net al. highlight the need for improved accuracy and effi-\\nciency in Handwritten Character Recognition.[16] Athira et\\nal. use transfer learning from Devanagari for recognizing\\nhandwritten Kannada characters. [17] Yadav et al. tackle\\nthe challenge of recognizing confusing characters in Kan-\\nnada documents using templates and classifiers. [18] Ganji\\net al. comprehensively cover phases of offline handwritten\\nHindi character recognition. [19] Ayyob et al. discuss OCR\\nchallenges in recognizing Telugu literature characters due to\\nlimited datasets and trained CNNs. [20] Srelekha et al. survey\\ndiverse methods used in Malayalam handwriting recogni-\\ntion, highlighting feature extraction and classification tech-\\nniques. [21] Md. Adnanul Islam et al. propose an effective\\nBengali-to-English translation technique, improving machine\\ntranslation accuracy. [22] Neha Bhadwal et al. propose a\\nsystem for translating Hindi text into Sanskrit, considering\\nlinguistic features of both languages. [23] Sitender et al.\\nutilize bilingual dictionaries and rule-based approaches for\\ntranslation. [24] Namrata Kharate et al. discuss challenges\\nin building translation models due to language differences\\nin syntax and morphology. [25] Kodabagi et al. focus on\\nneural machine translation (NMT) for Kannada to English,\\nachieving higher accuracy than statistical methods. [26]\\nSalunkhe et al. highlight challenges in translating complex\\nsentences and suggest simplification techniques.[27] Arikpo\\net al. propose a method for localizing and classifying digits\\ninto ten classes using Faster-RCNN. [28] Mardhotillah et al.\\npropose a methodology achieving a high accuracy of 97.56%\\nin translating sentences into Kannada.[29] Dhar et al. propose\\na system using parallel datasets for document translation.\\n[30] Soman et al. develop a transfer-based translator for\\nEnglish to Efik language translation. [31] Prajapati’s paper\\nevaluates CNN models for recognizing Devanagari charac-\\nters, highlighting the absence of a universal model. [32]\\nChoudhary et al. compare subword segmentation methods for\\ntranslating English to Dravidian languages. [33] Gogineni et\\nal. assess an NMT architecture’s effectiveness for translation,\\nemphasizing the impact of lengthy English sentences. [34]\\nAsha Hegde et al. explore pragmatic methods for examining\\nmachine translation between Tulu and Kannada. [35][36]\\nRoshan Fernandes et al. propose models recognizes hand-\\nwritten Kannada characters and predict emotions in videos.\\n2 VOLUME , 2023\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e25cf7ca-fe71-4b88-817e-36c98d84719e', embedding=None, metadata={'page_label': '3', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='[37] Zixin Dou et al. explored various machine learning\\nalgorithms and achieved favorable accuracy results. From the\\nliterature survey we have observed that Hybrid algorithms\\nare not considered for the evaluation of the handwritten Tulu\\ncharacter recognition. Expansion of the dataset has to be done\\nto increase the accuracy of the Tulu character recognition\\nmodel. More Preprocessing techniques can be applied to in-\\ncrease the accuracy of the Tulu character recognition model.\\nFrom the literature survey we have also found that there are\\nno existing translators for English to Tulu or Tulu to English\\nsince Tulu is a local language which is spoken in udupi\\nand Mangaluru region. Our research objective is to create\\na system that can translate the English language into Tulu,\\nas there are no existing translators available according to the\\nliterature survey. Our research endeavors to create a system\\nwith the goal to fill the gap in Tulu language translation\\ntools by translating English to Tulu and Tulu to English. To\\naddress the lack of Tulu language translators by developing a\\nsystem that can precisely translate English to Tulu and Tulu\\nto English, as no existing translators were identified during\\nthe literature survey.\\nIII. METHODOLOGY\\nA. TULU CHARACTER RECOGNITION\\nThe proposed method, as represented in Figure 1, follows\\nvarious steps including Image Pre-processing, Image Seg-\\nmentation, Feature Extraction, Classification using machine\\nlearning algorithms, and Performance Comparison.\\n1) Data Preparation and Collection\\nFigure 1 describes the methodology used for Tulu character\\nrecognition such as image collection which involves collect-\\ning various handwritten characters of about 62 classes which\\nincludes 50 characters and 12 numerical. Total 31000 images\\nwhich include 500 images of each class are collected.\\n2) Image Preprocessing\\nAugmentation techniques are being applied with rota-\\ntion_range = 40, zoom_range = 0.1, and brightness range\\nbetween 0.5, and 0.8 which are shown in figure 2. Below\\nare the different augmented images. Once the character is\\ndetected each character is cropped individually and converted\\ninto 28*28 pixels. Each image is converted into a Grayscale\\nand then a binary image to reduce the noise in the image\\nwhich is shown in figure 3.\\n(a) Ordinary Image (b) Grey Image (c) Binary Image\\nFIGURE 3. Image Color Conversion\\nAlgorithm 1Image Segmentation\\nSet image width to 1000\\nSet image height to 550\\nSet dim to (width, height)\\nResize the image to dim using cv2.INTER_AREA\\nConvert the resized image to grayscale\\nSet thresh to 90\\nCreate a binary image using thresholding with the OTSU\\nmethod on binaryImage\\nSet kernel to a size (2,1)\\nApply morphological operations for refinement\\nSet dilate_kernel to a rectangular structuring element of\\nsize (8,5)\\nApply morphological dilation to opening using di-\\nlate_kernel\\nFind contours on dilate with RETR_EXTERNAL and\\nCHAIN_APPROX_SIMPLE modes\\nif len(cnts) == 2 then\\nSet cnts to cnts[0]\\nend if\\nSet i to 4\\nfor each contour c in cnts do\\nSet rect to the bounding rectangle of c\\nif rect[2] < 20 OR rect[3] < 20 then\\ncontinue\\nend if\\nSet x, y, w, h to rect\\nWrite the subimage of binaryImage that corresponds to\\nrect to a file named str(i) + \".jpg\"\\nIncrement i by 1\\nend for\\n3) Image Segmentation\\nAfter the image preprocessing stage, the contour technique\\nis utilized to identify distinct shapes or patterns within the\\nprocessed image. This involves detecting these shapes, out-\\nlining their boundaries using bounding boxes, and potentially\\nrecognizing characters or text segments. Subsequently, these\\nsegmented areas are subjected to further analysis like charac-\\nter identification.\\nOnce the character is detected each character is cropped\\nindividually and converted into 28*28 pixels. Figure 4 and 5\\nshows the detection of Tulu numerical and characters.\\n4) Feature Extraction\\nPrinciple Component Analysis is applied on each individual\\ncropped image. In this process 784 feature of individual\\nimage is fed into PCA since images are in 28*28 pixel size.\\nPCA considers 0.98 information from the each image hence\\n291 features are considered from the image. Once feature\\nextraction is completed through the use of eigen vectors, the\\nlabels are encoded using the one-hot encoding technique.\\nThis is done to facilitate their input into machine learning\\nalgorithms for subsequent processing.\\nVOLUME , 2023 3\\nThis article has been accepted for publication in IEEE Access. This is the author\\'s version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='42794163-b1d9-41b8-bc7f-f44c981e139d', embedding=None, metadata={'page_label': '4', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"FIGURE 1. Block diagram of Tulu Character Recognition.\\nFIGURE 2. Different Augmented images\\nFIGURE 4. Tulu Numericals detection\\n5) Classification Using Machine Learning Algorithms\\nIn order to train our method on a dataset, we utilized\\npreparation with Convolutional Neural Network to train on\\nbureaucracy data. Multi-class categorization with a total of\\n62 classes, comprising 50 characters and 12 numerical.\\nFIGURE 5. Tulu character Detection\\nAlgorithm 2PCA for Dimensionality Reduction\\n1) Set PCA to keep 98% of the variance:\\n2) If variance threshold is not provided then\\n3) Set variance threshold to 0.98\\n4) Initialize pca with variance threshold\\n5) Fit the PCA model with the training data and transform\\n6) xtrain = Apply fit_transform method of pca with\\nx_train as input\\n7) xtest = Apply transform method of pca with x_test as\\ninput\\n8) Print the shape of xtrain and xtest\\n9) Print the number of principal components selected by\\npca\\n10) Print the number of features in the original dataset\\n4 VOLUME , 2023\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='a3bd2fe7-6fe9-4b74-a123-60f7361d0801', embedding=None, metadata={'page_label': '5', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='TABLE 1. CNN Layer Hyperparameters\\nLayer Hyperparameters\\nConv2D 3 ×3 Kernel size, ReLU activation, 64 filters\\nConv2D 3 ×3 Kernel size, ReLU activation, 32 filters\\nDropout (Core Layer) 0.3 Neurons\\nMaxPool2D 2 ×2 pool size\\nDense 64 Units, ReLU activation\\nDense 62 Units, Softmax activation\\nDropout (Core Layer) 0.3 Neurons\\nConv2D 3 ×3 Kernel size, ReLU activation, 128 filters\\nMaxPool2D 2 ×2 pool size\\nIn the analysis, the convolutional neural network displays\\ngreater accuracy when contrasted with the other evaluated\\nmachine learning algorithms. Table 1 and 2 gives the detailed\\nanalysis of the CNN hyperparameters.\\nTABLE 2. Hyperparameter Values\\nHyperparameter Value\\nRegularization term kernel regularizer with L2 regularization\\nBatch size 32\\nLoss function Categorical cross-entropy\\nLearning rate 0.001\\nEpochs 150\\nOptimizer Adam\\nB. RULE BASED LANGUAGE TRANSLATION FROM\\nENGLISH TO TULU\\nThe model comprises four modules in sequence. The initial\\nmodule processes English speech input, passing its output to\\nthe subsequent module, aiming to generate Tulu text as the\\nfinal result.Figure 6 illustrates the system architecture of the\\nlanguage translator.\\n1) Preparation and Collection of Dataset\\nCollection of the dataset was done manually which includes\\nwords in english, kannada and tulu language. Though we\\nonly make use of english and tulu words in the main trans-\\nlation, we collected the corresponding kannada words which\\ncan be used in near future, for further development. The total\\nnumber of words collected initially was 1481.Training words\\nfor rule based machine translation are shown in figure 7.\\n2) Algorithm\\nEnglish text is taken as input. Spacy was utilized to perform\\nParts of Speech tagging and Named Entity Recognition on\\nthe English text, with the goal of identifying any names or\\nlocations present. If such entities were detected, they were\\ntranscribed and stored separately. The resulting modified\\nEnglish text was then translated into Kannada. For each\\nword in the Kannada text, a word-to-word translation was\\nperformed from Kannada to English, with each English word\\nbeing checked against a database. If a match was found,\\nthe corresponding Tulu word was mapped to the English\\nword. If no match was found, no translation was performed.\\nFinally, the Tulu sentence was constructed based on the\\nKannada sentence structure, with any previously identified\\nnamed entities being reintroduced. All of these steps were\\ncombined to generate the final Tulu text. Algorithm 3 shows\\nthe step by step procedure for the rule based translation.\\nAlgorithm 3Translate Text Algorithm\\nInitialize ner_dict as an empty dictionary and pos_list as\\nan empty list.\\nTokenize and tag the input text using spaCy’s nlp()\\nfunction.\\nfor each token do\\nif token has a named entity type then\\nAdd token to ner_dict.\\nelse\\nAppend (token text, POS tag) to pos_list.\\nend if\\nend for\\nTranslate the input text from English to Kannada.\\nSplit the translated text into a list of words (l).\\nfor each word in l do\\nTranslate word from Kannada to English using Trans-\\nlator.\\nend for\\nFilter out stop words and exceptions from the translated\\nwords.\\nJoin the filtered words into a single string ( string1) and\\nsplit it into a list (string).\\nOpen and read a CSV file.\\nfor each row in the CSV file do\\nfor each word in string do\\nif word is a key in ner_dict then\\nReplace the word in string with ner_dict.\\nelse\\nConstruct a regex pattern \"^\" and match it against\\nthe word.\\nif there is a match then\\nReplace the word in string with the Tulu word.\\nend if\\nend if\\nend for\\nend for\\nC. NEURAL MACHINE TRANSLATION\\nNeural Machine Translation (NMT) is an automated trans-\\nlation method that utilizes neural networks to translate text\\nfrom one language to another, replacing Statistical Machine\\nTranslation (SMT) in many applications. The fundamental\\nconcept behind NMT is to use a deep neural network to\\nlearn the correlation between the source and target language.\\nThe neural network takes the source language text as a input\\nand generates the translated text in the target language as\\nVOLUME , 2023 5\\nThis article has been accepted for publication in IEEE Access. This is the author\\'s version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='597617c7-7510-48b6-857a-c293683facbd', embedding=None, metadata={'page_label': '6', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"FIGURE 6. Block diagram of Rule based Language Translation\\nFIGURE 7. Training words for rule based machine translation\\noutput. This network is trained on a large parallel corpus of\\nsentences in both languages. The process of neural machine\\ntranslation involves the computer automatically translating\\nsentences from one language to another.The steps involved\\nin neural machine translation are illustrated in Figure 7.\\nThe input layer converts the source sentence into numeri-\\ncal vectors. LSTM1 layer encodes the source sentence and\\ngenerates hidden states capturing its contextual information.\\nLSTM2 layer decodes the encoded information into the target\\nlanguage, utilizing the hidden states from LSTM1 layer.\\nThe output layer produces the final translation by computing\\nprobabilities for each target word and selecting the word with\\nthe highest probability. Figure 8 shows the structure of Neural\\nMachine Translation.\\nIn our methodology for English to Tulu neural machine\\ntranslation, we incorporated both forward and backward ap-\\nproaches. The forward approach involves training the model\\nto translate from English to Tulu, where the English sentence\\nis the input and the Tulu translation is the target. However, we\\nalso recognized the importance of the backward approach,\\nwhich involves training the model in the reverse direction,\\nfrom Tulu to English. The backward approach provides addi-\\ntional benefits by enabling the model to capture bidirectional\\nlanguage dependencies and improve the overall translation\\nquality. By training the model to translate from Tulu to\\nEnglish, we ensure that it learns to generate accurate and\\nfluent Tulu translations, leveraging the knowledge obtained\\nfrom both forward and backward training.\\n1) Data Collection and Preparation\\nTo train a neural machine translation model, we have used\\na 1000 parallel sentence of both english and tulu. Clean the\\nparallel corpus to remove noise and inconsistencies. This in-\\nvolves removing duplicate sentences, correcting typograph-\\nical errors, and normalizing punctuation, capitalization, and\\nformatting. Training sentences of neural machine translation\\nare shown in Figure 9.\\n2) Tokenization\\nThe dataset’s sentences are tokenized, meaning that each\\nsentence is converted into a sequence of integers where each\\ninteger represents a word. Separate tokenizers are utilized for\\nthe source and target languages.\\n3) Sequence Padding\\nAfter tokenization, the sequences are padded to ensure that\\nthey have the same length. This is essential since neural\\nnetworks demand input data to have the same shape. The\\nblock diagram of neural machine translation is displayed in\\nFigure 7.\\n4) Encoder Model\\nAn encoder model is built that takes the source language\\nembeddings as input and generates a fixed-size vector that\\n6 VOLUME , 2023\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='dab38340-363b-4842-8ae3-0084bb8debc8', embedding=None, metadata={'page_label': '7', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"FIGURE 8. Block diagram of Neural Machine Translation\\nFIGURE 9. Training sentences of neural machine translation\\nrepresents the entire input sequence. This model typically\\nuses an LSTM (Long Short-Term Memory) network, which\\nallows it to handle variable-length input sequences and cap-\\nture long-term dependencies in the input. The LSTM network\\nprocesses the input embeddings word by word and produces a\\nsequence of hidden states. The last hidden state of the LSTM\\nnetwork is then used as the fixed-size vector representation\\nof the input sequence.\\n5) Decoder Model\\nThe decoder model is designed to receive the embeddings\\nof the target language along with the output of the encoder\\nmodel as inputs, and generate the output sequence word by\\nword. Typically, an LSTM network is used in the decoder\\nmodel, which enables it to handle output sequences of vari-\\nFIGURE 10. Structure of Neural Machine Translation\\nable length and generate words based on previous words gen-\\nerated. As the target language embeddings and the encoder\\nmodel’s output are fed into the LSTM network, a sequence\\nof hidden states is produced. In each time step, the LSTM\\nnetwork of the decoder generates a probability distribution\\nover the target vocabulary using the current hidden state and\\nselects the subsequent word in the output sequence based on\\nthis distribution. Encoder decoder model is shown in Figure\\n8.\\n6) Training\\nThe training process combines training for both the encoder\\nand decoder models, using a loss function that computes the\\nvariance between the predicted and real output sequences.\\nThe LSTM network weights and other model parameters are\\noptimized using backpropagation through time. After train-\\ning, the models can be used to translate new input sequences\\nfrom the source language to the target language by encoding\\nthe input sequence using the encoder model and generating\\nthe output sequence word by word using the decoder model.\\nTable 3 describes the Hyperparameter of Encoder-Decoder\\nVOLUME , 2023 7\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e7080d76-d66d-4971-8aa0-6873a1038885', embedding=None, metadata={'page_label': '8', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"FIGURE 11. Encoder Decoder Model Structure\\nModel.\\nTABLE 3. Hyperparameter of Encoder-Decoder Model\\nEncoder\\nEmbedding dimension 256\\nLSTM units 256\\nDecoder\\nEmbedding dimension 256\\nLSTM units 256\\nReturn sequences True (to return sequences at each timestep)\\nReturn state True (to return the final internal state of the LSTM)\\nTraining\\nOptimizer Adam optimizer\\nLoss function Sparse categorical cross-entropy\\nNumber of epochs 500\\nBatch size 128\\n7) Evaluation\\nTo evaluate the model’s performance on the validation set,\\nmetrics such as precision, accuracy, F1- score and recall are\\ncalculated.\\nIV. RESULTS AND DISCUSSION\\nThis section presents the experiment results on recognizing\\nhandwritten Tulu characters. In the performance analysis, the\\nCNN model achieved an accuracy of 92% with the consid-\\nered dataset. This accuracy outperforms the other algorithms,\\nas Figure 10(c) depicts. Figures 10(a) and 10(b) illustrate\\nthe accuracy and loss measures of the CNN model over 150\\nepochs.The accuracy measure is determined by analyzing\\nthe performance of the model on both the validation and\\ntraining datasets, providing insights into its generalization\\ncapabilities. Figure 10(d) depicts the performance analysis\\nTulu character recognition model by considering parameters\\nsuch as f1-score, recall, and precision. In the analysis CNN\\nmodel has better score compared to the other algorithms.\\nFIGURE 12. CNN Model Accuracy Measure\\n8 VOLUME , 2023\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='a09be470-76b4-4aec-8a9c-8f058a96b3a0', embedding=None, metadata={'page_label': '9', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"FIGURE 13. CNN Model Loss Measure\\nFIGURE 14. Tulu Character Recognition Accuracy Classification\\nFIGURE 17. Performance analysis of rule based method\\nFIGURE 15. Performance Analysis of Tulu Character\\nFIGURE 16. Analysis of Blue score\\nFIGURE 18. ’a’ character detection\\nVOLUME , 2023 9\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='85885e14-112e-4e7e-b7da-937b6879174a', embedding=None, metadata={'page_label': '10', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"FIGURE 19. ‘one’ numerical detection\\nParameters Accuracy Precision Recall f1-score\\nWord Based 89% 95% 94% 94%\\nSentence Based 81% 91% 90% 91%\\nTABLE 4. Performance analysis of rule based machine translation\\nA. CLASSIFICATION PERFORMANCE COMPARISON\\nThe performance of the classification was evaluated using\\nthe Precision, F1 Score, and Recall metrics, as defined by\\nequations (1), (2), and (3). Figure 9(d) shows the performance\\nanalysis of Tulu character recongition.\\nPrecision:\\nPrecision = TP\\nFP + TP (1)\\nRecall:\\nRecall = TP\\nTP + FN (2)\\nF1 Score:\\nF1 Score = 2 · Precision · Recall\\nPrecision + Recall (3)\\nWhere:\\n• TP = True Positive\\n• TN = True Negative\\n• FP = False Positive\\n• FN = False Negative\\nFigures 11(c) and 11(d) illustrate the process of recogniz-\\ning Tulu characters using the trained model. In this process,\\neach Tulu character is inputted into the model, and the model\\nproduces the corresponding output in the form of either\\na Kannada character or a numerical representation. Figure\\n11(b) shows the experimental result of Text-based translation\\nfrom English to Tulu model has achieved 89% accuracy on\\nword-based translation and 81% on sentence-based transla-\\ntion considered dataset. For the performance analysis, the\\nfollowing parameters were taken into consideration: accu-\\nracy, precision, recall, and F1-score. Comparing word-based\\nanalysis to sentence-based analysis, the word-based approach\\nyielded better results. Figure 11(a) depicts the variation in\\nBlue score values for English to Tulu translation over 500\\niterations, with a peak value of 0.83. For the training of\\ntranslation from English to Tulu and viceversa we have\\nconsidered single line sentence which are simple and easier\\nfor the conversion. In contrast, the Blue score values for Tulu\\nto English translation range from 0.31 to 0.65 over the same\\niteration range. Table 4 shows the performance analysis of\\nrule-based machine Translation.\\nV. CONCLUSION AND FUTURE WORK\\nThe research aimed to develop an English-to-Tulu language\\ntranslator and a literature review of existing translators for\\nIndian and other languages was conducted. Although many\\napproaches provide accurate results for words and simple\\nphrases, accuracy decreases for complex sentences. To im-\\nprove accuracy, a survey paper was written based on col-\\nlected research papers, and a dataset was manually collected\\nand tested. A handwritten character recognition system was\\ndeveloped using CNN, achieving 92% accuracy for Tulu\\ncharacters and numerals. An algorithm using a rule-based\\nmethod was incorporated into the research work for English-\\nto-Tulu translation, achieving 89% accuracy for simple words\\nand sentences. Neural machine technology was applied to\\nincrease efficiency and achieved a blue score of 0.83. The\\nmodel is currently being evaluated using individual sen-\\ntences, while the assessment of phrases is slated for future\\nconsideration. However, accuracy decreased for complex\\nsentences, indicating the need for more dataset collection\\nto improve the system. Future work includes developing a\\nreal-time application with Tulu unicode and a more complex\\nmodel and phrases can be considered in the testing of the\\nmodel.\\nVI. CONFLICT OF INTEREST\\nAuthors do not have any conflict of interest.\\nREFERENCES\\n[1] Manimozhi, I. (2021, April). An Efficient Translation of Tulu to Kannada\\nSouth Indian Scripts using Optical Character Recognition. In 2021 5th In-\\nternational Conference on Computing Methodologies and Communication\\n(ICCMC) (pp. 952-957). IEEE.\\n[2] Bhat, S., Seshikala, G. (2021). Character recognition of Tulu script using\\nconvolutional neural network. In Advances in Artificial Intelligence and\\nData Engineering (pp. 121-131). Springer, Singapore.\\n[3] Anush Bijoor, Anusha, Kripashree Bhat, Sneesha D Shetty and\\nMr.Venugopala Rao A S A CNN-Based Approach for Recognition of\\nAncient Tigalari Handwritten Characters.\\n[4] Savitha, C. K., Antony, P. J. (2018, November). Machine learning ap-\\nproaches for recognition of offline tulu handwritten scripts. In Journal of\\nPhysics: Conference Series (V ol. 1142, No. 1, p. 012005). IOP Publishing.\\n[5] Rao, A. S., Sandhya, S., Anusha, K., Arpitha, C. N., Meghana, S.\\nN. (2020). Exploring deep learning techniques for kannada handwritten\\ncharacter recognition: A boon for digitization. International Journal of\\nAdvanced Science and Technology, 29(5), 11078-11093.\\n[6] Memon, J., Sami, M., Khan, R. A., Uddin, M. (2020). Handwritten op-\\ntical character recognition (OCR): A comprehensive systematic literature\\nreview (SLR). IEEE Access, 8, 142642-142668.\\n10 VOLUME , 2023\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='6ca68916-211f-4504-b619-bceb66e49ea1', embedding=None, metadata={'page_label': '11', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"[7] Albahli, S., Nawaz, M., Javed, A., Irtaza, A. (2021). An improved faster-\\nRCNN model for handwritten character recognition. Arabian Journal for\\nScience and Engineering, 46(9), 8509-8523.\\n[8] Bora, M. B., Daimary, D., Amitab, K., Kandar, D. (2020). Handwritten\\ncharacter recognition from images using CNN-ECOC. Procedia Computer\\nScience, 167, 2403-2409.\\n[9] Deore, S. P., Pravin, A. (2020). Devanagari handwritten character recogni-\\ntion using fine-tuned deep convolutional neural network on trivial dataset.\\nS¯adhan¯a, 45(1), 1-13.\\n[10] Khandokar, I., Hasan, M., Ernawan, F., Islam, S., Kabir, M. N. (2021,\\nJune). Handwritten character recognition using convolutional neural net-\\nwork. In Journal of Physics: Conference Series (V ol. 1918, No. 4, p.\\n042152). IOP Publishing.\\n[11] Guha, R., Das, N., Kundu, M., Nasipuri, M., Santosh, K. C. (2020).\\nDevNet: an efficient CNN architecture for handwritten Devanagari charac-\\nter recognition. International Journal of Pattern Recognition and Artificial\\nIntelligence, 34(12), 2052009.\\n[12] Rani, N. S., BR, P. (2022). Robust recognition technique for handwrit-\\nten Kannada character recognition using capsule networks. International\\nJournal of Electrical Computer Engineering (2088-8708), 12(1).\\n[13] Hamdan, Y . B. (2021). Construction of statistical SVM based recognition\\nmodel for handwritten character recognition. Journal of Information Tech-\\nnology, 3(02), 92-107.\\n[14] Vinjit, B. M., Bhojak, M. K., Kumar, S., Chalak, G. (2020, July). A\\nReview on Handwritten Character Recognition Methods and Techniques.\\nIn 2020 International Conference on Communication and Signal Processig\\n(ICCSP) (pp. 1224-1228). IEEE.\\n[15] Rani, N. S., Subramani, A. C., Kumar, A., Pushpa, B. R. (2020, July).\\nDeep learning network architecture based kannada handwritten character\\nrecognition. In 2020 Second International Conference on Inventive Re-\\nsearch in Computing Applications (ICIRCA) (pp. 213-220). IEEE.\\n[16] BJ, B. N., Athira, M. R., Prajwal, M. L. (2021, May). Kannada Confusing\\nCharacter Recognition and Classification Using Random Forest and SVM.\\nIn 2021 3rd International Conference on Signal Processing and Commu-\\nnication (ICPSC) (pp. 537-541). IEEE.\\n[17] Yadav, M., Purwar, R. K., Mittal, M. (2018). Handwritten Hindi character\\nrecognition: a review. IET Image Processing, 12(11), 1919-1933.\\n[18] Ganji, T., Velpuru, M. S., Dugyala, R. (2021). Multi variant handwritten\\ntelugu character recognition using transfer learning. In IOP Conference\\nSeries: Materials Science and Engineering (V ol. 1042, No. 1, p. 012026).\\n[19] Ayyoob, M. P., Ilyas, P. M. (2021). A review on various techniques used\\nto recognize off-line handwritten Malayalam characters. Malaya Journal\\nof Matematik (MJM), 9(1, 2021).\\n[20] Srelekha S, “Machine Translation between Malayalam and English”,\\nResearch gate 2020.\\n[21] Md. Adnanul Islam, Md. Saidul Hoque Anik and A. B. M. Alim Al Islam,\\n“An Enhanced RBMT: When RBMT Outperforms Modern Data-Driven\\nTranslators”, IETE Technical Review 2022.\\n[22] Neha Bhadwal,Prateek Agrawal, Vishu Madaan‡ “Machine Translation\\nfrom Hindi to Sanskrit”, Scalable Computing: Practice and Experience,\\n2020.\\n[23] Sitender and Seema Bawa, “A Sanskrit-to-English machine translation\\nusing hybridization Rule based”, Neural Computing and Applications\\n2021.\\n[24] Namrata Kharate, Seth Darren and Varsha Patil, “ Handling challenges in\\nrule based machine translation from marathi to english”, Research gate\\n2019.\\n[25] Kodabagi, M. M., Angadi, S. A. (2016, December). A methodology for\\nmachine translation of simple sentences from Kannada to English lan-\\nguage. In 2016 2nd International Conference on Contemporary Computing\\nand Informatics (IC3I) (pp. 237-241). IEEE.\\n[26] Salunkhe, P., Kadam, A. D., Joshi, S., Patil, S., Thakore, D., Jadhav,\\nS. (2016, March). Hybrid machine translation for English to Marathi: A\\nresearch evaluation in Machine Translation:(Hybrid translator). In 2016\\nInternational Conference on Electrical, Electronics, and Optimization\\nTechniques (ICEEOT) (pp. 924-931). IEEE.\\n[27] ARIKPO, I., DICKSON, I. (2018). Development of an automated\\nEnglish-to-local-language translator using Natural Language Processing.\\nInternational Journal of Scientific Engineering Research, 9(7), 378-383.\\n[28] Mardhotillah, R., Dirgantoro, B., Setianingsih, C. (2020, December).\\nSpeaker Recognition for Digital Forensic Audio Analysis using Support\\nVector Machine. In 2020 3rd International Seminar on Research of Infor-\\nmation Technology and Intelligent Systems (ISRITI) (pp. 514-519). IEEE.\\n[29] Dhar, P., Bisazza, A., van Noord, G. (2021, August). Optimal word\\nsegmentation for neural machine translation into Dravidian languages. In\\nProceedings of the 8th Workshop on Asian Translation (W AT2021) (pp.\\n181-190).\\n[30] Soman, K. P., Kumar, M. A., Premjith, B. (2019). Neural Machine\\nTranslation System for English to Indian Language Translation Using\\nMTIL Parallel Corpus.\\n[31] Prajapati, R., Parikh, V . V ., Majumder, P. (2021, April). Irlab-daiict@\\ndravidianlangtech-eacl2021: Neural machine translation. In Proceedings\\nof the First Workshop on Speech and Language Technologies for Dravid-\\nian Languages (pp. 262-265).\\n[32] Choudhary, H., Rao, S., Rohilla, R. (2020). Neural Machine Translation\\nfor Low-Resourced Indian Languages. arXiv preprint arXiv:2004.13819.\\n[33] Gogineni, S., Suryanarayana, G., Surendran, S. K. (2020, September). An\\nEffective Neural Machine Translation for English to Hindi Language. In\\n2020 International Conference on Smart Electronics and Communication\\n(ICOSEC) (pp. 209-214). IEEE.\\n[34] Hegde, A., Shashirekha, H. L., Madasamy, A. K., Chakravarthi, B. R.\\n(2023, March). A Study of Machine Translation Models for Kannada-\\nTulu. In Third Congress on Intelligent Systems: Proceedings of CIS 2022,\\nV olume 1 (pp. 145-161). Singapore: Springer Nature Singapore.\\n[35] Fernandes, R., Rodrigues, A. P. (2019, August). Kannada handwritten\\nscript recognition using machine learning techniques. In 2019 IEEE in-\\nternational conference on distributed computing, VLSI, electrical circuits\\nand robotics (DISCOVER) (pp. 1-6). IEEE.\\n[36] Fernandes, R., Rodrigues, A. P. (2022, December). Emotion Detection\\nin Multimedia Data Using Convolution Neural Network. In 2022 Interna-\\ntional Conference on Artificial Intelligence and Data Engineering (AIDE)\\n(pp. 157-161). IEEE.\\n[37] Dou, Z., Sun, Y ., Zhu, J., Zhou, Z. (2023). The Evaluation Prediction\\nSystem for Urban Advanced Manufacturing Development. Systems, 11(8),\\n392.\\nVOLUME , 2023 11\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='07e90451-643e-4a0e-be33-84d246af65f5', embedding=None, metadata={'page_label': '12', 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf', 'file_type': 'application/pdf', 'file_size': 1427571, 'creation_date': '2025-02-28', 'last_modified_date': '2025-02-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"PRATHWINI was born in Mangaluru, India in\\n1998. She received the B.E. degree in Informa-\\ntion Science and Engineering in 2019 and MTech\\ndegree in Computer Science and Engineering in\\n2023 from the VTU, Belagavi, India.\\nCurrently working as an Assistant Professor in\\nthe Department of Master of Computer Applica-\\ntions at NMAM Institute of Technology, Nitte,\\nIndia. She is the author of 2 research paper. Her\\nresearch interests include Natural Language Pro-\\ncessing, Machine Learning and Deep Learning.\\nANISHA P RODRIGUES was born in Man-\\ngaluru, India in 1985. She received the B.E. degree\\nin Electrical and Electronics Engineering in 2006,\\nMTech degree in Computer Science and Engineer-\\ning in 2012 and PhD degree in the area of Big Data\\nAnalytics in 2020 from the VTU, Belagavi, India.\\nSince 2012, she is working as Assistant Profes-\\nsor in the Department of Computer Science and\\nEngineering at NMAM Institute of Technology,\\nNitte, India. She is the author of 3 book chapters\\nand 20 articles. Her research interests include Natural Language Processing,\\nMachine Learning, Deep Learning and Big Data Analytics.\\nP . VIJAYA was born in Tiruchirappalli, India\\nin 1969. She received the Diploma in Electron-\\nics and Communication in 1987, B.E. degree in\\nElectronics and Communication Engineering in\\n1995, MTech degree in Computer Science and\\nEngineering in 2002 and PhD degree in the area\\nof Information Retrieval in 2017 from Karpagam\\nAcademy of Higher Education, Coimbatore, In-\\ndia.\\nCurrently she is working in Department of\\nMathematics and Computer Science, Bawshar, Muscat, Sultanate. She is the\\nauthor of 4 book chapters and 36 articles. Her research interests include\\nInformation Retrieval, Machine Learning, Deep Learning and Big Data\\nAnalytics.\\nROSHAN FERNANDES was born in Man-\\ngaluru, India in 1979. He received the B.E. de-\\ngree in Computer Science and Engineering in\\n2001 from Mangalore University, MTech degree\\nin Computer Engineering in 2007 and PhD degree\\nin the area of Mobile Web Services in 2019 from\\nthe VTU, Belagavi, India.\\nCurrently he is working as the Associate Pro-\\nfessor in the Department of Computer Science and\\nEngineering at NMAM Institute of Technology,\\nNitte, India. He has a teaching experience of 18 years in this Institution. He\\nis the author of 4 book chapters and 18 articles. His research interests include\\nMobile Web Services, Natural Language Processing, Machine Learning, and\\nDeep Learning.\\n12 VOLUME , 2023\\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \\ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3355470\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_page = docs[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = docs[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_docs = front_page + content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.29s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.58s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.03s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.50s/it]\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.75s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "100%|██████████| 15/15 [01:27<00:00,  5.83s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline = IngestionPipeline(transformations=transformations)\n",
    "nodes = pipeline.run(documents=main_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_label': '1',\n",
       " 'file_name': 'Tulu_Language_Text_Recognition_and_Translation.pdf',\n",
       " 'file_path': 'data/Tulu_Language_Text_Recognition_and_Translation.pdf',\n",
       " 'file_type': 'application/pdf',\n",
       " 'file_size': 1427571,\n",
       " 'creation_date': '2025-02-28',\n",
       " 'last_modified_date': '2025-02-28',\n",
       " 'document_title': 'Title: \"Comparative Exploration of Advanced Machine Translation Techniques for Tulu Language: A Comprehensive Analysis of Convolutional Neural Networks, Rule-based Method, and Hybrid Approach\"\\n\\nThis title encapsulates the core elements of the described document. It highlights the focus on Tulu language translation using advanced machine techniques, specifically detailing three approaches: a) Convolutional Neural Networks (CNN), b) rule-based method, and c) hybrid approach. The title also emphasizes the comparative nature by including \"comprehensive analysis.\"',\n",
       " 'questions_this_excerpt_can_answer': '1. **What is the current status and recognition of the Tulu language according to the document?**\\n   - This question seeks a detailed response on how the Tulu language, primarily spoken in Karnataka, has been acknowledged by the Indian constitution as the second language and ongoing efforts to include it in the 8th Schedule.\\n\\n2. **How does the hybrid machine translation approach enhance English-to-Tulu and Tulu-to-English translations compared to the rule-based and Convolutional Neural Network (CNN) methods, as reported by the research team?**\\n   - This question prompts for a comparison of the performance of these three distinct translation techniques on the same data sets—handwritten characters, parallel sentence dataset, and parallel word dataset. It seeks to understand how hybrid machine translation contributes to improving accuracy rates beyond what rule-based methods and CNN achieve in both directions (English to Tulu and Tulu to English).\\n\\n3. **What were the respective accuracy rates achieved by the rule-based approach for word-based analysis, sentence-based analysis, the neural network Encoder-Decoder model with LSTM, and the hybrid machine translation for translating English into the Tulu language?**\\n   - This question focuses on specific performance metrics of the three different methods to translate from English to Tulu. It requires a direct comparison of these scores (word-based analysis 89%, sentence-based analysis 81%) to understand how each method contributes to overall translation quality, which might not be easily accessible in other resources about machine translation techniques.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
